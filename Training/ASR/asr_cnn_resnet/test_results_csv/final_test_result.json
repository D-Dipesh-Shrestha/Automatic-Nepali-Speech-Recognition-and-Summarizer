{"model_0.1_10000_15000": {"Average WER": 0.678804347826087, "Average WER Accuracy": 0.321195652173913, "Average CER": 0.18080561489166921, "Average CER Accuracy": 0.8191943851083308}, "model_0.1_30000_35000": {"Average WER": 0.8195652173913044, "Average WER Accuracy": 0.1804347826086956, "Average CER": 0.4151663106499847, "Average CER Accuracy": 0.5848336893500152}, "model_0.1_35k_40k": {"Average WER": 0.8494565217391304, "Average WER Accuracy": 0.15054347826086956, "Average CER": 0.39258468111077205, "Average CER Accuracy": 0.607415318889228}, "model_0.1_25k_30k_lt_0.4sec": {"Average WER": 0.8081521739130435, "Average WER Accuracy": 0.1918478260869565, "Average CER": 0.3944919133353677, "Average CER Accuracy": 0.6055080866646323}, "model_0.1_5000_10000": {"Average WER": 0.5625, "Average WER Accuracy": 0.4375, "Average CER": 0.31301495270064084, "Average CER Accuracy": 0.6869850472993592}, "model_0.1_50k_55k": {"Average WER": 0.9271739130434783, "Average WER Accuracy": 0.07282608695652171, "Average CER": 0.5816295392126946, "Average CER Accuracy": 0.41837046078730544}, "model_0.1_45k_50k": {"Average WER": 0.9179347826086957, "Average WER Accuracy": 0.08206521739130435, "Average CER": 0.5423405553860238, "Average CER Accuracy": 0.45765944461397623}, "model_0.1_55k_60k": {"Average WER": 0.9119565217391304, "Average WER Accuracy": 0.08804347826086956, "Average CER": 0.5716356423558132, "Average CER Accuracy": 0.4283643576441868}, "model_0.1_15000_20000": {"Average WER": 0.746195652173913, "Average WER Accuracy": 0.25380434782608696, "Average CER": 0.2326060421116875, "Average CER Accuracy": 0.7673939578883124}, "model_0.1_60k_65k": {"Average WER": 0.941304347826087, "Average WER Accuracy": 0.05869565217391304, "Average CER": 0.6506713457430576, "Average CER Accuracy": 0.3493286542569424}, "model_0.1_40k_45k": {"Average WER": 0.9016304347826087, "Average WER Accuracy": 0.09836956521739126, "Average CER": 0.5023649679584986, "Average CER Accuracy": 0.4976350320415014}, "model_0.1_65k_above": {"Average WER": 0.8891304347826087, "Average WER Accuracy": 0.11086956521739133, "Average CER": 0.4774946597497711, "Average CER Accuracy": 0.5225053402502289}, "model_0.1_20k_25k_lt_4sec": {"Average WER": 0.8065217391304348, "Average WER Accuracy": 0.1934782608695652, "Average CER": 0.3272810497406164, "Average CER Accuracy": 0.6727189502593836}, "model_0.1_dropout_5_10sec": {"Average WER": 0.5103260869565217, "Average WER Accuracy": 0.4896739130434783, "Average CER": 0.1155782728104974, "Average CER Accuracy": 0.8844217271895026}, "model-lt-4sec-first-5000": {"Average WER": 0.44456521739130433, "Average WER Accuracy": 0.5554347826086956, "Average CER": 0.10230393652731157, "Average CER Accuracy": 0.8976960634726885}, "model-4-5sec-0.1dropout": {"Average WER": 0.4733695652173913, "Average WER Accuracy": 0.5266304347826087, "Average CER": 0.10390601159597193, "Average CER Accuracy": 0.8960939884040281}}